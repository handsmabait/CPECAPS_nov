@misc{venkatrayappa2024survey3dhumanbody,
  title        = {Survey of 3D Human Body Pose and Shape Estimation Methods for Contemporary Dance Applications},
  author       = {Darshan Venkatrayappa and Alain Tremeau and Damien Muselet and Philippe Colantoni},
  year         = {2024},
  eprint       = {2401.02383},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  url          = {https://arxiv.org/abs/2401.02383}
}

@article{zhangmediapipe,
  author       = {Zhang, Fan and Bazarevsky, Valentin and Vakunov, Andrey and Tkachenka, Andrei and Sung, George and Chang, Chuo-Ling and Grundmann, Matthias},
  title        = {MediaPipe Hands: On-device Real-time Hand Tracking},
  journal      = {CoRR},
  year         = {2020},
  eprint       = {2006.10214},
  archivePrefix= {arXiv},
  url          = {https://arxiv.org/abs/2006.10214}
}

@article{oudah2020hand,
  author  = {Oudah, Munir and Al-Naji, Ali Abdulelah and Chahl, Javaan},
  title   = {Hand Gesture Recognition Based on Computer Vision: A Review of Techniques},
  journal = {Journal of Imaging},
  year    = {2020},
  month   = jul,
  volume  = {6},
  pages   = {73},
  doi     = {10.3390/jimaging6080073}
}

@article{Protopapadakis2018dancepose,
  author  = {Protopapadakis, Eftychios and Voulodimos, Athanasios and Doulamis, Anastasios and Camarinopoulos, Stephanos and Doulamis, Nikolaos and Miaoulis, Georgios},
  title   = {Dance Pose Identification from Motion Capture Data: A Comparison of Classifiers},
  journal = {Technologies},
  year    = {2018},
  month   = mar,
  volume  = {6},
  doi     = {10.3390/technologies6010031}
}

@article{xu_adaptive_2022,
  author  = {Xu, Xixia and Zou, Qi and Lin, Xue},
  title   = {Adaptive Hypergraph Neural Network for Multi-Person Pose Estimation},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year    = {2022},
  month   = jun,
  volume  = {36},
  number  = {3},
  pages   = {2955--2963},
  doi     = {10.1609/aaai.v36i3.20201},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/20201}
}

@article{RAHMAN2025125929,
  author  = {Rahman, Md Mijanur and Uzzaman, Ashik and Khatun, Fatema and Aktaruzzaman, Md and Siddique, Nazmul},
  title   = {A comparative study of advanced technologies and methods in hand gesture analysis and recognition systems},
  journal = {Expert Systems with Applications},
  year    = {2025},
  volume  = {266},
  pages   = {125929},
  issn    = {0957-4174},
  doi     = {10.1016/j.eswa.2024.125929},
  url     = {https://www.sciencedirect.com/science/article/pii/S0957417424027969}
}

@misc{ultraleapHandTrackingOverview,
  author  = {Ultraleap},
  title   = {Ultraleap Hand Tracking Overview},
  year    = {2025},
  url     = {https://docs.ultraleap.com/hand-tracking},
  note    = {Accessed: 2025-10-13}
}

@misc{verma2024enhancingsignlanguagedetection,
  title        = {Enhancing Sign Language Detection through Mediapipe and Convolutional Neural Networks (CNN)},
  author       = {Verma, Aditya Raj and Singh, Gagandeep and Meghwal, Karnim and Ramji, Banawath and Dadheech, Praveen Kumar},
  year         = {2024},
  eprint       = {2406.03729},
  archivePrefix= {arXiv},
  primaryClass = {cs.LG},
  url          = {https://arxiv.org/abs/2406.03729}
}

@article{ZHAO202566,
  author  = {Zhao, Hong and Du, Bojing and Jia, Yongju and Zhao, Hui},
  title   = {DanceFormer: Hybrid transformer model for real-time dance pose estimation and feedback},
  journal = {Alexandria Engineering Journal},
  year    = {2025},
  volume  = {121},
  pages   = {66--76},
  issn    = {1110-0168},
  doi     = {10.1016/j.aej.2025.02.014},
  url     = {https://www.sciencedirect.com/science/article/pii/S1110016825001814}
}

@misc{leililiu2023dancemovement,
  author    = {Lei, Ping and Li, Nana and Liu, Haidong},
  title     = {Dance Movement Recognition Based on Gesture},
  booktitle = {Proceedings},
  year      = {2023},
  month     = jan,
  pages     = {448--452},
  isbn      = {978-94-6463-057-2},
  doi       = {10.2991/978-94-6463-058-9_73}
}

@article{tolgyessy2021skeletontracking,
  author  = {T{\"o}lgyessy, Michal and Dekan, Martin and Chovanec, \v{L}ubo\v{s}},
  title   = {Skeleton Tracking Accuracy and Precision Evaluation of Kinect V1, Kinect V2, and the Azure Kinect},
  journal = {Applied Sciences},
  year    = {2021},
  volume  = {11},
  number  = {12},
  pages   = {5756},
  doi     = {10.3390/app11125756},
  url     = {https://www.mdpi.com/2076-3417/11/12/5756}
}

@article{sun2025dancemovement,
  author  = {Sun, Jia and Song, Lewis},
  title   = {Dance Movement Pose Estimation in Complex Scenes Based on Improved High-Resolution Networks},
  journal = {Taiwan Ubiquitous Information},
  year    = {2025},
  volume  = {10},
  number  = {1},
  month   = feb,
  issn    = {2414-8105},
  note    = {Journal of Network Intelligence},
  doi     = {10.1234/jni.2025.01.1234},
  url     = {http://example.com}
}

@article{Erdem2025,
  author  = {B{\"u}y{\"u}kg{\"o}ko\u{g}lan, Erdem and U\u{g}uz, Sinan},
  title   = {Development of a Performance Evaluation System in Turkish Folk Dance Using Deep Learning-Based Pose Estimation},
  journal = {Tehni\v{c}ki vjesnik -- Technical Gazette},
  year    = {2025},
  month   = sep,
  volume  = {32},
  pages   = {1817--1824},
  doi     = {10.17559/TV-20241218002203}
}

@article{linjustdance,
  author  = {Lin, Jih-Hsuan},
  title   = {Just Dance: The Effects of Exergame Feedback and Controller Use on Physical Activity and Psychological Outcomes},
  journal = {Games for Health Journal},
  year    = {2015},
  volume  = {4},
  number  = {3},
  pages   = {183--189},
  doi     = {10.1089/g4h.2014.0092},
  note    = {PMID: 26182062},
  url     = {https://doi.org/10.1089/g4h.2014.009}
}

@article{yuxiong2019,
  author  = {Yu, Xiaoqun and Xiong, Shuping},
  title   = {A Dynamic Time Warping Based Algorithm to Evaluate Kinect-Enabled Home-Based Physical Rehabilitation Exercises for Older People},
  journal = {Sensors},
  year    = {2019},
  volume  = {19},
  number  = {13},
  pages   = {2882},
  doi     = {10.3390/s19132882},
  url     = {https://www.mdpi.com/1424-8220/19/13/2882},
  note    = {PubMedID: 31261746}
}

@article{trallis2019,
  author  = {Rallis, Ioannis and Protopapadakis, Eftychios and Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Bardis, Georgios},
  title   = {Choreographic Pattern Analysis from Heterogeneous Motion Capture Systems Using Dynamic Time Warping},
  journal = {Technologies},
  year    = {2019},
  volume  = {7},
  number  = {3},
  pages   = {56},
  doi     = {10.3390/technologies7030056},
  url     = {https://www.mdpi.com/2227-7080/7/3/56}
}

@article{article,
  author  = {Song, Liangchen and Yu, Gang and Yuan, Junsong and Liu, Zicheng},
  title   = {Human pose estimation and its application to action recognition: A survey},
  journal = {Journal of Visual Communication and Image Representation},
  year    = {2021},
  volume  = {76},
  pages   = {103055},
  doi     = {10.1016/j.jvcir.2021.103055}
}

@misc{zheng2023deeplearningbasedhumanpose,
  title        = {Deep Learning-Based Human Pose Estimation: A Survey},
  author       = {Zheng, Ce and Wu, Wenhan and Chen, Chen and Yang, Taojiannan and Zhu, Sijie and Shen, Ju and Kehtarnavaz, Nasser and Shah, Mubarak},
  year         = {2023},
  eprint       = {2012.13392},
  archivePrefix= {arXiv},
  primaryClass = {cs.CV},
  url          = {https://arxiv.org/abs/2012.13392}
}

@article{BENGAMRA2021104282,
  author  = {Ben Gamra, Miniar and Akhloufi, Moulay A.},
  title   = {A review of deep learning techniques for 2D and 3D human pose estimation},
  journal = {Image and Vision Computing},
  year    = {2021},
  volume  = {114},
  pages   = {104282},
  doi     = {10.1016/j.imavis.2021.104282},
  url     = {https://www.sciencedirect.com/science/article/pii/S0262885621001876}
}

@article{SARKAR2022116424,
  author  = {Sarkar, Arya and Banerjee, Avinandan and Singh, Pawan Kumar and Sarkar, Ram},
  title   = {3D Human Action Recognition: Through the eyes of researchers},
  journal = {Expert Systems with Applications},
  year    = {2022},
  volume  = {193},
  pages   = {116424},
  doi     = {10.1016/j.eswa.2021.116424},
  url     = {https://www.sciencedirect.com/science/article/pii/S0957417421017115}
}

@article{s23042182,
  author  = {Morshed, Md Golam and Sultana, Tangina and Alam, Aftab and Lee, Young-Koo},
  title   = {Human Action Recognition: A Taxonomy-Based Survey, Updates, and Opportunities},
  journal = {Sensors},
  year    = {2023},
  volume  = {23},
  number  = {4},
  pages   = {2182},
  doi     = {10.3390/s23042182},
  url     = {https://www.mdpi.com/1424-8220/23/4/2182}
}

@Article{app13042700,
AUTHOR = {Kim, Jong-Wook and Choi, Jin-Young and Ha, Eun-Ju and Choi, Jae-Ho},
TITLE = {Human Pose Estimation Using MediaPipe Pose and Optimization Method Based on a Humanoid Model},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {4},
ARTICLE-NUMBER = {2700},
URL = {https://www.mdpi.com/2076-3417/13/4/2700},
ISSN = {2076-3417},
ABSTRACT = {Seniors who live alone at home are at risk of falling and injuring themselves and, thus, may need a mobile robot that monitors and recognizes their poses automatically. Even though deep learning methods are actively evolving in this area, they have limitations in estimating poses that are absent or rare in training datasets. For a lightweight approach, an off-the-shelf 2D pose estimation method, a more sophisticated humanoid model, and a fast optimization method are combined to estimate joint angles for 3D pose estimation. As a novel idea, the depth ambiguity problem of 3D pose estimation is solved by adding a loss function deviation of the center of mass from the center of the supporting feet and penalty functions concerning appropriate joint angle rotation range. To verify the proposed pose estimation method, six daily poses were estimated with a mean joint coordinate difference of 0.097 m and an average angle difference per joint of 10.017 degrees. In addition, to confirm practicality, videos of exercise activities and a scene of a person falling were filmed, and the joint angle trajectories were produced as the 3D estimation results. The optimized execution time per frame was measured at 0.033 s on a single-board computer (SBC) without GPU, showing the feasibility of the proposed method as a real-time system.},
DOI = {10.3390/app13042700}
}


@article{THARATIPYAKUL2024e36589,
title = {Deep learning-based human body pose estimation in providing feedback for physical movement: A review},
journal = {Heliyon},
volume = {10},
number = {17},
pages = {e36589},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e36589},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024126205},
author = {Atima Tharatipyakul and Thanawat Srikaewsiew and Suporn Pongnumkul},
keywords = {Pose estimation, Movement assessment, Augmented feedback, Physical movement, Review},
abstract = {Pose estimation has various applications in analyzing human body movement and behavior, including providing feedback to users about their movements so they can adjust and improve their movement skills. To investigate the current research status and possible gaps, we searched Scopus and Web of Science for articles that (1) human ‘body’ pose estimation is used and (2) user movement is assessed and communicated. We used either a bottom-up or top-down approach to analyze 45 articles for methods used to estimate human body pose, assess movement, provide feedback to users, as well as methods to evaluate them. Our review found that pose estimation systems typically used CNNs while movement assessment methods varied from mathematical formulas or models, rule-based approaches, to machine learning. Feedback was primarily presented visually in verbal forms and nonverbal forms. The experiments to evaluate each part ranged from the use of public datasets to human participants. We found that pose estimation libraries play an important role in the advancement of this field. Nevertheless, the effectiveness and factors for choosing movement assessment methods for a new context are still unclear. In the end, we suggest that studies about feedback prioritization and erroneous feedback are needed.}
}

@article{Raheb2019,
author = {El Raheb, Katerina and Stergiou, Marina and Katifori, Akrivi and Ioannidis, Yannis},
year = {2019},
month = {06},
pages = {1-37},
title = {Dance Interactive Learning Systems: A Study on Interaction Workflow and Teaching Approaches},
volume = {52},
journal = {ACM Computing Surveys},
doi = {10.1145/3323335}
}
