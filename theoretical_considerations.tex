\section{Human Pose Estimation}

Human pose estimation is the process of predicting the pose of human body parts. The data are typically derived from RGB images or videos. Given that certain motions are motivated by human actions, detecting poses is a critical aspect of human action recognition (Song et al., 2021). It has a wide range of applications such as human-computer interaction, motion analysis, augmented reality, and virtual reality. The resulting output of human pose estimation is a skeleton-like representation of the human body consisting of nodes and limbs (Zheng et al., 2020). There are two main types of human pose estimation, namely 2D and 3D. 2D pose estimation consists of predicting the posture of each of the body’s key points in a 2D plane, considering the X and Y axes. As for 3D pose estimation, it considers the Z axis, situating each point in a 3D space. It goes without saying that 3D estimation is more difficult in comparison to 2D estimation in process and complexity due to underlying issues such as noisy backgrounds, clothing, lighting, undetected joints, or occlusion (Ben Gamra \& Akhloufi, 2021).

\section{Human Action Recognition}

Human action recognition (HAR) is the process of detecting human actions to classify them through single-sensor data, RGB image or video data, or three-dimensional depth and inertial data (Sakar et al., 2022). In the field of computer vision, one of the most challenging aspects is the automatic and precise identification of human activity. Over the years, there has been a significant increase in feature learning-based representations for human action recognition as a result of the widespread utilization of deep learning-based features. There are various applications of HAR — for instance, automated surveillance systems that make use of AI and machine learning algorithms to identify human actions for safety and security. Such tasks, however, are made difficult due to factors such as changing environments, occlusion, different viewpoints, execution pace, and biometric variation. Furthermore, the human body varies from person to person in factors such as size, appearance, and shape. However, advancements in Convolutional Neural Networks (CNNs) have resulted in significant progress in human action recognition through improvements in classification, segmentation, and object detection. This largely applies to image-related tasks rather than videos, as neural network models struggle to capture temporal information in videos due to the lack of substantial datasets (Morshed et al., 2022).
